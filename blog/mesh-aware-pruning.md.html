

<meta charset="utf-8" emacsmode="-*- markdown -*-">
<title>Adaptive Mesh-Guided Pruning</title>
<link rel="stylesheet" href="script/report.css">
<script src="script/data.js"></script>
<script src="script/ImageBox.js"></script>

<script type="text/javascript">
    let imageBoxUI;  // Global reference to the instance for re-creation
    let resizeTimeout;  // For debouncing

    function updateImageBox() {
        // Clear existing content to avoid duplicates
        const content = document.getElementById("content");
        content.innerHTML = '';  // Reset the div

        // Dynamically set based on current window size (90% of width for padding, cap at 2560px)
        imageBoxSettings.width = Math.min(window.innerWidth * 0.9, 2560);
        imageBoxSettings.height = imageBoxSettings.width * (1080 / 1920);  // Preserve 16:9 aspect ratio

        // Re-create the ImageBox
        if (data['imageBoxes']) {
            imageBoxUI = new ImageBox(content, data['imageBoxes'], "Mesh Aware Pruning");
        }
    }

    function setup() {
        updateImageBox();  // Initial setup

        // Add resize listener with debounce (200ms delay)
        window.addEventListener('resize', () => {
            clearTimeout(resizeTimeout);
            resizeTimeout = setTimeout(updateImageBox, 200);
        });
    }
</script>
**Adaptive Mesh-Guided Pruning for Mesh-in-the-Loop Gaussian Splatting**

We present Adaptive Mesh-Guided Pruning, an extension of Mesh-in-the-Loop Gaussian Splatting that introduces geometric awareness into the pruning of 3D Gaussian primitives. While MILo effectively combines photometric optimization with mesh supervision, its pruning relies mainly on appearance cues, often retaining redundant off-surface Gaussians "floaters" that increase memory use and distort reconstructed surfaces. AMGP addresses this issue by incorporating each Gaussian's signed distance to the reconstructed mesh into a unified importance score, blending photometric contribution, opacity, and geometric proximity. This mesh-aware strategy preserves Gaussians near the surface, resulting in compact, surface-aligned models that maintain fidelity and improve geometric coherence.

# Introduction

3D Gaussian Splatting has transformed neural scene representation, enabling high-fidelity novel view synthesis and real-time rendering from multi-view images. By representing a scene as a collection of anisotropic Gaussians, 3DGS achieves greater efficiency than Neural Radiance Fields. However, aggressive densification strategies, which duplicate Gaussians to capture fine details, often produce millions of primitives, including redundant off-surface elements that waste memory, slow inference, and impair mesh reconstruction.

Mesh-in-the-Loop Gaussian Splatting mitigates this issue by coupling Gaussian optimization with an explicit mesh extracted differentiably through a signed distance function pipeline. Yet, MILo's pruning remains largely photometric, focusing on rendering contributions and visibility metrics. This approach preserves visual quality but often neglects geometric consistency, allowing floaters that disrupt mesh regularization and surface smoothness.

To overcome these drawbacks, Adaptive Mesh-Guided Pruning introduces a geometric bias in the pruning process by accounting for each Gaussian's proximity to the reconstructed mesh. This encourages a thin, surface-centered Gaussian band, producing coherent volumetric-surface hybrids while reducing primitives. Inspired by recent pruning methods like uncertainty- and gradient-based approaches, AMGP uniquely leverages mesh geometry for guidance, improving both efficiency and reconstruction accuracy, particularly valuable for robotics, AR, and 3D content creation.

# Mathematical Formulation

Our method builds upon MILo's training setup. At iteration $t$, the scene is represented by Gaussians $\mathcal{G}*t = {g_i^t}*{i=1}^{N_t}$ and a differentiably extracted mesh $M_t$. Each Gaussian $g_i^t$ has:

* a 3D position $x_i^t$,
* covariance matrix $\Sigma_i^t$,
* opacity logit $o_i^t$ converted via $\alpha_i^t = \sigma(o_i^t)$, and
* appearance features $f_i^t$.

Training minimizes a joint loss $\mathcal{L}(\mathcal{G}*t, M_t)$ balancing photometric accuracy and mesh consistency. Pruning occurs periodically after a warm-up phase $T*{\text{warm}}$, at discrete iterations $\mathcal{T}_{\mathrm{prune}}$. When triggered, the pruning operator $\mathcal{P}_t$ refines $\mathcal{G}*t$ into a smaller set $\mathcal{G}*{t^+} = \mathcal{P}_t(\mathcal{G}_t, M_t)$.

## Core Signals

We assess each Gaussian using three complementary signals:

1. Photometric Contribution and Visibility
   For each sampled camera view $v \in \mathcal{V}_t$, we compute per-Gaussian accumulated weights $w_i^{(v,t)} \ge 0$, representing how strongly each Gaussian contributes to rendered pixels. We then aggregate these contributions across all sampled views:

   $$W_i^t = \sum_{v \in \mathcal{V}_t} w_i^{(v,t)}.$$

   A high $W_i^t$ indicates that a Gaussian plays a significant role in image formation.

   To ensure robustness across perspectives, we track visibility via the number of views where a Gaussian appears among the top contributors:

   $$c_{\mathrm{vis},i}^t = \sum_{v \in \mathcal{V}_t} \mathbf{1}{ w_i^{(v,t)} \text{ ranks in the top quantile of view } v }.$$

   This metric favors Gaussians that consistently influence multiple views, reducing bias from viewpoint-specific noise.

2. Geometric Proximity to the Mesh
   The core novelty of AMGP lies in introducing explicit geometric regularization through proximity-based weighting. We measure how far each Gaussian's center lies from the current mesh surface using the signed distance function:

   $$d_i^t = \varphi_{M_t}(x_i^t),$$

   where $\varphi_{M_t}$ gives positive values outside the surface and negative inside. Computing this directly can be expensive, so we approximate it efficiently via the learned occupancy $o_i^t$ from MILo's SDF branch:

   $$d_i^t \approx \beta (1 - 2 o_i^t), \quad d_i^t = \text{clamp}(d_i^t, [-\beta, \beta]),$$

   where $\beta$ defines the width of the surface-aligned pruning band. This formulation allows geometry-aware pruning without additional mesh queries or gradients, which is key to scalability.

   Intuitively, Gaussians near the mesh ($|d_i^t| \approx 0$) are geometrically meaningful, while those far away are likely floaters or noise.

3. Opacity Weighting
   The effective opacity $\alpha_i^t = \sigma(o_i^t)$ reflects the transparency of each Gaussian. Including this term suppresses nearly transparent primitives, ensuring only visually and structurally relevant Gaussians are preserved.

## Mesh-Aware Importance Scoring

The novelty of our pruning formulation lies in the joint photometric-geometric importance score:

$$I_i^t = \alpha_i^t \cdot W_i^t \cdot \exp(-\lambda |d_i^t|),$$

where $\lambda > 0$ controls how quickly importance decays with distance from the mesh.

* The first term $\alpha_i^t$ ensures that faint, low-opacity Gaussians contribute less.
* The second term $W_i^t$ measures visual contribution across views.
* The third term $\exp(-\lambda |d_i^t|)$ is our novel mesh-aware weighting, which exponentially penalizes Gaussians as they drift from the surface band.

This score unifies appearance and geometry into a single continuous importance metric. It differs from prior pruning schemes, which rely solely on photometric or uncertainty signals, by introducing a differentiable geometric prior through the mesh.

## Adaptive Pruning via CDF Thresholding

To prune adaptively rather than by a fixed number of Gaussians, we use a cumulative distribution function (CDF) strategy. We sort scores in ascending order and compute their cumulative sum:

$$S_k^t = \sum_{j=1}^k I_{(j)}^t, \quad S_{N_t}^t = \sum_{i=1}^{N_t} I_i^t.$$

We then find the smallest $k_\rho^t$ satisfying:

$$\frac{S_{k_\rho^t}^t}{S_{N_t}^t} > 1 - \rho,$$

where $\rho \in [0,1]$ is the retained importance mass (typically 0.99). The corresponding threshold $\theta_t = I_{(k_\rho^t)}^t$ defines which Gaussians are kept:

$$\text{keep}_i^t = \mathbf{1}{ I_i^t > \theta_t }.$$

This ensures the pruning adapts to the scene's complexity and preserves the majority of meaningful contributions.

## Implementation Example

Below is a PyTorch implementation snippet for MILo's GaussianModel class, using mesh-aware importance and occupancy-based SDF approximation:

```python
@torch.no_grad()
def culling_with_mesh_aware_pruning(self, scene, render_simp, iteration, args, pipe, background):
    imp_score = torch.zeros(self._xyz.shape[0], device='cuda')
    views = scene.getTrainCameras_warn_up(iteration, args.warn_until_iter)

    count_rad = torch.zeros_like(imp_score).unsqueeze(1)
    count_vis = torch.zeros_like(imp_score).unsqueeze(1)

    for view in views:
        render_pkg = render_simp(view, self, pipe, background)
        accum_weights = render_pkg["accum_weights"]
        radii = render_pkg["radii"]

        imp_score += accum_weights
        count_rad += (radii > 0).float().unsqueeze(1)
        count_vis += (accum_weights > 0).float().unsqueeze(1)

    self.set_occupancy_mode("occupancy_shift")
    occupancy = self.get_occupancy[:, 0].squeeze()
    beta = args.mesh_prune_band
    sdf_values = beta * (1.0 - 2.0 * occupancy).clamp(-beta, beta)
    dist = torch.abs(sdf_values)

    alpha = self.get_opacity.squeeze()
    I = alpha * imp_score * torch.exp(-args.mesh_prune_lambda * dist)

    non_prune_mask = init_cdf_mask(importance=I, thres=args.mesh_prune_keep_mass)
    prune_mask = (count_vis <= args.mesh_prune_min_vis)[:, 0] | (~non_prune_mask) | (dist > args.mesh_prune_band)
    self.prune_points(prune_mask)
```

# Comparison to MILo's Dense Pruning

MILo's original pruning relies solely on photometric importance, which can preserve redundant floaters and lead to irregular surfaces.
In contrast, AMGP integrates geometric proximity and opacity, yielding more compact and surface-aligned Gaussian sets.
This improves reconstruction accuracy and efficiency, reducing Gaussian counts by around 50% while maintaining PSNR.

<div class="content" id="content"></div>

| Method          | # Gaussians |
| --------------- | ----------- |
| MILo (Original) | 4 113 643   |
| AMGP (Ours)     | 1 755 688   |

# References

[1] B. Kerbl et al. 3D Gaussian Splatting for Real-Time Radiance Field Rendering. ACM TOG (SIGGRAPH), 42(4):1-14, 2023.

[2] A. Gu√©don et al. MILo: Mesh-in-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction. arXiv:2406.24096, 2024.

[3] M. Hanson et al. PUP 3D-GS: Principled Uncertainty Pruning for 3D Gaussian Splatting. CVPR, 2025.

[4] M. Tatarchenko et al. Efficient Compression of 3D Gaussian Splats through Pruning. BMVC, 2024.

[5] Z. Duan et al. LP-3DGS: Learning to Prune 3D Gaussian Splatting. arXiv:2405.18784, 2024.

[6] J. Ye et al. 3D Gaussian Primitive Pruning While Avoiding Catastrophic Scene Destruction. arXiv:2405.17793, 2024.

<!-- Markdeep: -->

<style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style>

<script src="markdeep.min.js" charset="utf-8"></script>

<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>

<script>window.markdeepOptions = {onLoad: setup};window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
